{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import torch.nn.utils.rnn as RNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING_SESSION_LABEL</th>\n",
       "      <th>trial</th>\n",
       "      <th>IA_ID</th>\n",
       "      <th>item</th>\n",
       "      <th>list</th>\n",
       "      <th>IA_LABEL</th>\n",
       "      <th>wordlength</th>\n",
       "      <th>condition</th>\n",
       "      <th>is_critical</th>\n",
       "      <th>is_spill1</th>\n",
       "      <th>...</th>\n",
       "      <th>duration_firstpass</th>\n",
       "      <th>duration_firstfixation</th>\n",
       "      <th>fix_count</th>\n",
       "      <th>avg_pupil</th>\n",
       "      <th>IA_REGRESSION_IN_COUNT</th>\n",
       "      <th>IA_REGRESSION_OUT_COUNT</th>\n",
       "      <th>saccade_length</th>\n",
       "      <th>saccade_duration</th>\n",
       "      <th>go_past_time</th>\n",
       "      <th>sentenceCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10m23r2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Viel</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>1408.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.376792</td>\n",
       "      <td>16</td>\n",
       "      <td>236</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10m23r2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Geld</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>424</td>\n",
       "      <td>264</td>\n",
       "      <td>3</td>\n",
       "      <td>1379.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>71.519648</td>\n",
       "      <td>160</td>\n",
       "      <td>424</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10m23r2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>wurde</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10m23r2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>investiert,</td>\n",
       "      <td>11</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>420</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.401223</td>\n",
       "      <td>12</td>\n",
       "      <td>420</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10m23r2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>bevor</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "      <td>1242.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42.311819</td>\n",
       "      <td>12</td>\n",
       "      <td>296</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>9m23r1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Verteidigung</td>\n",
       "      <td>12</td>\n",
       "      <td>filler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.810675</td>\n",
       "      <td>20</td>\n",
       "      <td>168</td>\n",
       "      <td>filler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11172</th>\n",
       "      <td>9m23r1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Europas</td>\n",
       "      <td>7</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119.788355</td>\n",
       "      <td>24</td>\n",
       "      <td>224</td>\n",
       "      <td>filler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11173</th>\n",
       "      <td>9m23r1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>erh√∂ht</td>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.117033</td>\n",
       "      <td>20</td>\n",
       "      <td>332</td>\n",
       "      <td>filler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11174</th>\n",
       "      <td>9m23r1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>werden</td>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.649126</td>\n",
       "      <td>16</td>\n",
       "      <td>244</td>\n",
       "      <td>filler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11175</th>\n",
       "      <td>9m23r1</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>sollten.</td>\n",
       "      <td>8</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1164</td>\n",
       "      <td>filler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11176 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RECORDING_SESSION_LABEL  trial  IA_ID  item  list      IA_LABEL  \\\n",
       "0                     10m23r2     12      1     1     2          Viel   \n",
       "1                     10m23r2     12      2     1     2          Geld   \n",
       "2                     10m23r2     12      3     1     2         wurde   \n",
       "3                     10m23r2     12      4     1     2   investiert,   \n",
       "4                     10m23r2     12      5     1     2         bevor   \n",
       "...                       ...    ...    ...   ...   ...           ...   \n",
       "11171                  9m23r1     10     12    28     1  Verteidigung   \n",
       "11172                  9m23r1     10     13    28     1       Europas   \n",
       "11173                  9m23r1     10     14    28     1        erh√∂ht   \n",
       "11174                  9m23r1     10     15    28     1        werden   \n",
       "11175                  9m23r1     10     16    28     1      sollten.   \n",
       "\n",
       "       wordlength condition  is_critical  is_spill1  ...  duration_firstpass  \\\n",
       "0               4      none            0          0  ...                 236   \n",
       "1               4      none            0          0  ...                 424   \n",
       "2               5      none            0          0  ...                   0   \n",
       "3              11      none            0          0  ...                 420   \n",
       "4               5      none            0          0  ...                 296   \n",
       "...           ...       ...          ...        ...  ...                 ...   \n",
       "11171          12    filler            0          0  ...                 168   \n",
       "11172           7      none            0          0  ...                 224   \n",
       "11173           6      none            0          0  ...                 332   \n",
       "11174           6      none            0          0  ...                 244   \n",
       "11175           8      none            0          0  ...                 160   \n",
       "\n",
       "       duration_firstfixation  fix_count    avg_pupil  IA_REGRESSION_IN_COUNT  \\\n",
       "0                         236          1  1408.000000                       0   \n",
       "1                         264          3  1379.333333                       2   \n",
       "2                           0          0     0.000000                       0   \n",
       "3                         268          3  1290.000000                       1   \n",
       "4                         296          2  1242.500000                       1   \n",
       "...                       ...        ...          ...                     ...   \n",
       "11171                     168          2   497.000000                       0   \n",
       "11172                     224          1   493.000000                       0   \n",
       "11173                     332          1   472.000000                       0   \n",
       "11174                     244          1   477.000000                       0   \n",
       "11175                     160          1   495.000000                       0   \n",
       "\n",
       "       IA_REGRESSION_OUT_COUNT  saccade_length  saccade_duration  \\\n",
       "0                            0       72.376792                16   \n",
       "1                            0       71.519648               160   \n",
       "2                            1        0.000000                 0   \n",
       "3                            0       65.401223                12   \n",
       "4                            0       42.311819                12   \n",
       "...                        ...             ...               ...   \n",
       "11171                        0       91.810675                20   \n",
       "11172                        0      119.788355                24   \n",
       "11173                        0       95.117033                20   \n",
       "11174                        0       58.649126                16   \n",
       "11175                        1        0.000000                 0   \n",
       "\n",
       "       go_past_time  sentenceCondition  \n",
       "0               236            control  \n",
       "1               424            control  \n",
       "2                 0            control  \n",
       "3               420            control  \n",
       "4               296            control  \n",
       "...             ...                ...  \n",
       "11171           168             filler  \n",
       "11172           224             filler  \n",
       "11173           332             filler  \n",
       "11174           244             filler  \n",
       "11175          1164             filler  \n",
       "\n",
       "[11176 rows x 29 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RECORDING_SESSION_LABEL', 'trial', 'IA_ID', 'item', 'list', 'IA_LABEL',\n",
       "       'wordlength', 'condition', 'is_critical', 'is_spill1', 'is_spill2',\n",
       "       'is_spill3', 'filler', 'LF', 'HF', 'function_word', 'other_filler',\n",
       "       'composite', 'fixation_duration', 'duration_firstpass',\n",
       "       'duration_firstfixation', 'fix_count', 'avg_pupil',\n",
       "       'IA_REGRESSION_IN_COUNT', 'IA_REGRESSION_OUT_COUNT', 'saccade_length',\n",
       "       'saccade_duration', 'go_past_time', 'sentenceCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "dropped = data.copy()\n",
    "\n",
    "dropped[[\"condition\", \"sentenceCondition\"]] = dropped[[\"condition\", \"sentenceCondition\"]].map(lambda x: x.replace(\"none\", \"0\"))\n",
    "dropped[[\"condition\", \"sentenceCondition\"]] = dropped[[\"condition\", \"sentenceCondition\"]].map(lambda x: x.replace(\"control\", \"0\"))\n",
    "dropped[[\"condition\", \"sentenceCondition\"]] = dropped[[\"condition\", \"sentenceCondition\"]].map(lambda x: x.replace(\"pseudo\", \"1\"))\n",
    "dropped[[\"condition\", \"sentenceCondition\"]] = dropped[[\"condition\", \"sentenceCondition\"]].map(lambda x: x.replace(\"filler\", \"0\"))\n",
    "\n",
    "dropped.drop([\"condition\", \"IA_ID\", \"item\", \"list\", \"IA_LABEL\", \"wordlength\", \"is_critical\", \n",
    "              'is_spill1', 'is_spill2', 'is_spill3', 'filler', 'LF', 'HF', 'function_word', 'other_filler', \"composite\"], axis=1, inplace=True)\n",
    "\n",
    "sentences = dropped.groupby(['RECORDING_SESSION_LABEL', 'trial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(851,) (851, 18, 10) (851,)\n"
     ]
    }
   ],
   "source": [
    "label_array = np.array([])\n",
    "features_array = []\n",
    "for item in sentences:\n",
    "    label_array = np.append(label_array, item[1][\"sentenceCondition\"].unique().astype(int).item())\n",
    "    features = item[1].drop(['RECORDING_SESSION_LABEL', 'trial', 'sentenceCondition'], axis=1).to_numpy()\n",
    "    #print(features.shape)\n",
    "    features_array.append(features)\n",
    "\n",
    "def pad_to_same_size(lists):\n",
    "    maxlen = max([len(l) for l in lists])\n",
    "    return [np.concatenate((np.zeros((maxlen - l.shape[0], l.shape[1])), l), axis=0) for l in lists]\n",
    "lengths = np.array([len(l) for l in features_array])\n",
    "padded_features_array = np.array(pad_to_same_size(features_array))\n",
    "print(label_array.shape, padded_features_array.shape, lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.900117508813161\n"
     ]
    }
   ],
   "source": [
    "print(1 - label_array.sum()/len(label_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return features, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "dataset = CustomDataset(features=padded_features_array, labels=label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, batch_size):\n",
    "    \n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=generator)\n",
    "    #train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, validation_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader, validation_dataloader, test_dataloader = split_data(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 3 3\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([32, 18, 10]) torch.Size([32])\n",
      "torch.Size([9, 18, 10]) torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader), len(validation_dataloader), len(test_dataloader))\n",
    "for batch in train_dataloader:\n",
    "    input, target = batch\n",
    "    print(input.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, dataloader, optimizer, training=\"train\"):\n",
    "   \n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    if training == \"train\":\n",
    "        model.train()\n",
    "    elif training == \"validation\":\n",
    "        model.eval()\n",
    "    elif training == \"test\":\n",
    "        model.eval()\n",
    "    else:\n",
    "        raise ValueError(\"training argument must be either 'train', 'validation' or 'test'\")\n",
    "        \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    cumulative_loss = 0\n",
    "    prediction_list = []\n",
    "    label_list = []\n",
    "    for sample in dataloader:\n",
    "        input, targets = sample[0].float().to(device), sample[1].type(torch.LongTensor).to(device)\n",
    "        output = model(input)\n",
    "        loss_value = loss_function(output, targets)\n",
    "        cumulative_loss += loss_value.item()\n",
    "\n",
    "        if training == \"train\":\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        predictions = output.to('cpu').detach().numpy().argmax(axis=1)\n",
    "        target_labels = targets.to('cpu').detach().numpy()\n",
    "        total += len(predictions)\n",
    "        correct += accuracy_score(target_labels, predictions, normalize=False)\n",
    "        prediction_list.extend(predictions)\n",
    "        label_list.extend(target_labels)  \n",
    "    f1 = f1_score(label_list, prediction_list)\n",
    "    accuracy = accuracy_score(label_list, prediction_list)\n",
    "    confusion = confusion_matrix(label_list, prediction_list)\n",
    "\n",
    "    return cumulative_loss, accuracy, f1, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneableModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, layer_size, dropout_rate, n_layers):\n",
    "        super(TuneableModel, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=layer_size, bidirectional=False, \n",
    "                                  num_layers=n_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.output_layer = torch.nn.Linear(layer_size, 2)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(layer_size)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear = torch.nn.Linear(layer_size, layer_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.lstm(x)\n",
    "        x = x[0][:, -1, :]\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sample\n",
    "def evaluate(params):\n",
    "    dropout, hidden_size, learning_rate, batch_size, n_hidden = params\n",
    "\n",
    "    max_epochs = 1000\n",
    "    max_patience = 10\n",
    "    \n",
    "    PATH = \"model.pt\"\n",
    "\n",
    "    train_dataloader, validation_dataloader, test_dataloader = split_data(dataset, batch_size)\n",
    "    last_loss = 1000000\n",
    "    torch.manual_seed(seed)\n",
    "    input_size = train_dataloader.dataset[0][0].shape[1]\n",
    "    model = TuneableModel(input_size, hidden_size, dropout, n_hidden)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # training\n",
    "        train_loss, train_accuracy, train_f1, train_confusion = train_test(model, train_dataloader, optimizer, training=\"train\")\n",
    "        train_loss, train_accuracy, train_f1 = round(train_loss, 2), round(train_accuracy, 4), round(train_f1, 2)\n",
    "        # validation at end of epoch\n",
    "        validation_loss, validation_accuracy, validation_f1, validation_confusion = train_test(model, validation_dataloader, optimizer, training=\"validation\")\n",
    "        validation_loss, validation_accuracy, validation_f1 = round(validation_loss, 2), round(validation_accuracy, 4), round(validation_f1, 2)\n",
    "        if validation_loss < last_loss:\n",
    "            last_loss = validation_loss\n",
    "            current_patience = 0\n",
    "        else:\n",
    "            if current_patience == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': last_loss,\n",
    "                    }, PATH)\n",
    "            current_patience += 1\n",
    "        if current_patience == max_patience:\n",
    "            #print(f\"Early stopping at epoch {epoch}\")\n",
    "            break   \n",
    "        #if epoch % 10 == 0 and epoch != 0:\n",
    "            #print(f\"Epoch {epoch}\\nvalidation loss: {round(validation_loss, 2)}\\nvalidation accuracy: {validation_accuracy*100}%\\nvalidation f1: {validation_f1}\\n\")\n",
    "\n",
    "    # Testing once patience is reached\n",
    "    torch.manual_seed(seed)\n",
    "    model = TuneableModel(input_size, hidden_size, dropout, n_hidden)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    test_loss, test_accuracy, test_f1, test_confusion = train_test(model, test_dataloader, optimizer, training=\"test\")\n",
    "    test_loss, test_accuracy, test_f1 = round(test_loss, 2), round(test_accuracy, 4), round(test_f1, 2)\n",
    "    #print(f\"Model {i} at epoch {checkpoint['epoch']} test results: accuracy: {test_accuracy*100}% f1: {test_f1}\")\n",
    "\n",
    "    return test_accuracy, test_f1, test_confusion\n",
    "    # print(f\"Average accuracy: {round(np.mean(accuracies), 2)}%\")\n",
    "    # print(f\"Average f1: {round(np.mean(f1s), 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "params_nn ={\n",
    "    #'dropout': [x/10 for x in list(range(0, 11, 3))][:3],\n",
    "    'dropout': [0.5],\n",
    "    'hidden_size': list(range(100, 101, 100)),\n",
    "    'learning_rate':[0.01, 0.001, 0.0001, 0.00001],\n",
    "    'batch_size':[16, 32],\n",
    "    'n_hidden': list(range(2, 5, 1))\n",
    "}\n",
    "parameter_expansion = list(product(*params_nn.values()))\n",
    "print(len(parameter_expansion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[300], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, p \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(parameter_expansion)):\n\u001b[0;32m      3\u001b[0m     dropout, hidden_size, learning_rate, batch_size, n_hidden \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m----> 4\u001b[0m     accuracy, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     model_performance \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: dropout, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: learning_rate, \n\u001b[0;32m      6\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_hidden\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_hidden, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[0;32m      7\u001b[0m     results[i] \u001b[38;5;241m=\u001b[39m model_performance\n",
      "Cell \u001b[1;32mIn[298], line 20\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     train_loss, train_accuracy, train_f1 \u001b[38;5;241m=\u001b[39m train_test(model, train_dataloader, optimizer, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     train_loss, train_accuracy, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(train_loss, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;28mround\u001b[39m(train_accuracy, \u001b[38;5;241m4\u001b[39m), \u001b[38;5;28mround\u001b[39m(train_f1, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# validation at end of epoch\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i, p in tqdm(enumerate(parameter_expansion)):\n",
    "    dropout, hidden_size, learning_rate, batch_size, n_hidden = p\n",
    "    accuracy, f1 = evaluate(p)\n",
    "    model_performance = {\"dropout\": dropout, \"hidden_size\": hidden_size, \"learning_rate\": learning_rate, \n",
    "              \"batch_size\": batch_size, \"n_hidden\": n_hidden, \"accuracy\": accuracy, \"f1\": f1}\n",
    "    results[i] = model_performance\n",
    "    print(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = (0.5, 400, 0.0002, 32, 5)\n",
    "accuracy, f1, confusion = evaluate(best_params)\n",
    "print(\"Accuracy and f1 for best parameters: \", accuracy, f1)\n",
    "print(\"Confusion matrix:\\n\", confusion)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = pd.DataFrame.from_dict(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
